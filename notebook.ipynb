{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87ce03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langgraph.graph.message import AnyMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages, MessagesState\n",
    "from typing import Annotated\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "import operator\n",
    "from pydantic import BaseModel\n",
    "from pydantic import Field\n",
    "from typing import List\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86fde65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73d5b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23919a3",
   "metadata": {},
   "source": [
    "### Simple Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "343aabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "562f7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65f89f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b710b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77495135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2d9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_call_node(state):\n",
    "    return {\"messages\" : [llm.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947056a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106428f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.set_entry_point('node1')\n",
    "graph.add_node('node1', model_call_node)\n",
    "graph.add_edge('node1', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bde526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57fe7c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langgraph.graph.state.CompiledStateGraph"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "011ebb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage('can you explain me how you get build')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c409c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.invoke({'messages': messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f9820da",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_message = [HumanMessage('ok now explain me how can i do it')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53da8b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='can you explain me how you get build', additional_kwargs={}, response_metadata={}, id='5b0d0c99-a94b-45e0-9252-58bb8567fef8'),\n",
       " AIMessage(content='Okay, let\\'s break down how I, as a large language model, am \"built.\" It\\'s a multi-faceted process involving data, architecture, training, and ongoing refinement.  Think of it like building a house: you need materials (data), a blueprint (architecture), construction workers (training algorithms), and ongoing maintenance (refinement).\\n\\n**1. Data: The Foundation**\\n\\n*   **Massive Text and Code Datasets:** I am trained on an enormous amount of text and code data. This data comes from a variety of sources, including:\\n    *   **The Internet:**  Web pages, articles, blog posts, forums, and other publicly available text.\\n    *   **Books:**  A vast collection of published books.\\n    *   **Code Repositories:**  Code from platforms like GitHub, covering many programming languages.\\n    *   **Other Sources:**  Scientific papers, news articles, and other specialized datasets.\\n*   **Data Cleaning and Preprocessing:** The raw data is often messy and needs to be cleaned and preprocessed. This involves:\\n    *   **Removing irrelevant content:**  Filtering out noise, advertisements, and low-quality text.\\n    *   **Tokenization:**  Breaking down the text into smaller units called \"tokens\" (usually words or parts of words).\\n    *   **Normalization:**  Converting text to a consistent format (e.g., lowercase, removing punctuation).\\n    *   **Data Augmentation:**  Sometimes, the data is augmented to increase its diversity and improve the model\\'s robustness.\\n\\n**2. Architecture: The Blueprint**\\n\\n*   **Transformer Networks:**  The core architecture used in most modern large language models, including me, is based on the \"Transformer\" neural network architecture.\\n*   **Key Components of the Transformer:**\\n    *   **Attention Mechanism:**  This is the heart of the Transformer. It allows the model to focus on the most relevant parts of the input when processing it.  Instead of treating all words equally, the attention mechanism assigns weights to different words based on their importance in the context.\\n    *   **Encoder:**  Processes the input sequence and creates a representation of it.\\n    *   **Decoder:**  Generates the output sequence based on the encoded representation.\\n    *   **Multi-Head Attention:**  The attention mechanism is applied multiple times in parallel (\"multiple heads\") to capture different aspects of the input.\\n    *   **Feedforward Neural Networks:**  After the attention layers, feedforward neural networks are used to further process the information.\\n    *   **Residual Connections and Layer Normalization:**  These techniques help to stabilize training and improve performance.\\n*   **Scaling Up:**  Large language models are characterized by their massive size, often with billions or even trillions of parameters (the weights and biases in the neural network).  The more parameters, the more complex patterns the model can learn.\\n\\n**3. Training: The Construction Process**\\n\\n*   **Self-Supervised Learning:**  I am trained using a technique called \"self-supervised learning.\" This means that the model learns from the data itself, without explicit labels.\\n*   **Training Objectives:**  Common training objectives include:\\n    *   **Language Modeling:**  Predicting the next word in a sequence.  The model is given a sequence of words and asked to predict the word that comes next. This forces the model to learn the statistical relationships between words and phrases.\\n    *   **Masked Language Modeling (MLM):**  Randomly masking some of the words in a sequence and asking the model to predict the masked words.  This helps the model to understand the context of words and their relationships to each other.\\n    *   **Next Sentence Prediction (NSP):**  Given two sentences, predicting whether the second sentence follows the first.  This helps the model to understand the relationships between sentences and paragraphs.\\n*   **Optimization:**  The model\\'s parameters are adjusted during training to minimize the loss function (the difference between the model\\'s predictions and the actual values).  This is done using optimization algorithms like stochastic gradient descent (SGD) or Adam.\\n*   **Distributed Training:**  Training large language models requires massive computational resources.  The training process is typically distributed across many GPUs or TPUs (Tensor Processing Units) to speed it up.\\n\\n**4. Refinement: Ongoing Maintenance and Improvement**\\n\\n*   **Fine-Tuning:**  After the initial pre-training, the model can be fine-tuned on specific tasks or datasets.  This involves training the model on a smaller, more focused dataset to improve its performance on a particular task.  For example, a language model could be fine-tuned for question answering, text summarization, or machine translation.\\n*   **Reinforcement Learning from Human Feedback (RLHF):**  This is a technique used to align the model\\'s behavior with human preferences.  Human evaluators provide feedback on the model\\'s responses, and this feedback is used to train a reward model.  The reward model is then used to train the language model using reinforcement learning.\\n*   **Continuous Learning:**  The model is continuously updated with new data and improved training techniques.  This helps to keep the model up-to-date and improve its performance over time.\\n*   **Safety and Bias Mitigation:**  Efforts are made to mitigate biases in the model and ensure that it is used responsibly.  This involves carefully curating the training data, developing techniques to detect and remove biases, and implementing safety mechanisms to prevent the model from generating harmful or offensive content.\\n\\n**In Summary:**\\n\\nI am \"built\" through a complex process of:\\n\\n1.  **Gathering and preparing massive amounts of text and code data.**\\n2.  **Designing a powerful neural network architecture (Transformer).**\\n3.  **Training the model on the data using self-supervised learning.**\\n4.  **Refining the model through fine-tuning, reinforcement learning, and continuous learning.**\\n\\nThis process requires significant computational resources, expertise in machine learning, and ongoing research and development.  The field is constantly evolving, and new techniques are being developed to improve the performance, safety, and efficiency of large language models.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--6cc66ebe-6893-45fd-86c7-8a62dfb14aea-0', usage_metadata={'input_tokens': 8, 'output_tokens': 1300, 'total_tokens': 1308, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content='ok now explain me how can i do it', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state['messages'] + new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89487c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = graph.invoke({'messages': state['messages'] + new_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eee5740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down how you can build your own language model. Be warned: building a *large* language model like me requires significant resources and expertise. However, you can definitely build smaller, simpler models to learn the concepts and gain practical experience. Here's a roadmap:\n",
      "\n",
      "**I. Foundational Knowledge:**\n",
      "\n",
      "*   **Programming:**  Python is the dominant language for machine learning.  You'll need to be comfortable with Python syntax, data structures, and libraries.\n",
      "*   **Linear Algebra and Calculus:**  A basic understanding of these mathematical concepts is essential for understanding how neural networks work.\n",
      "*   **Machine Learning Fundamentals:**  Learn the basics of machine learning, including:\n",
      "    *   Supervised vs. Unsupervised Learning\n",
      "    *   Neural Networks (especially feedforward networks)\n",
      "    *   Backpropagation\n",
      "    *   Optimization algorithms (e.g., Gradient Descent, Adam)\n",
      "    *   Evaluation metrics (e.g., accuracy, precision, recall)\n",
      "*   **Natural Language Processing (NLP) Fundamentals:**  Learn the basics of NLP, including:\n",
      "    *   Tokenization\n",
      "    *   Word Embeddings (e.g., Word2Vec, GloVe)\n",
      "    *   Recurrent Neural Networks (RNNs) and LSTMs (though Transformers are now more common)\n",
      "    *   Sequence-to-Sequence models\n",
      "\n",
      "**II. Tools and Libraries:**\n",
      "\n",
      "*   **TensorFlow or PyTorch:** These are the two most popular deep learning frameworks.  Choose one and become proficient in it.  PyTorch is often considered more beginner-friendly, but TensorFlow has a larger ecosystem.\n",
      "*   **Hugging Face Transformers:** This library provides pre-trained models and tools for working with Transformers.  It's a great way to get started quickly.\n",
      "*   **NLTK or spaCy:** These are NLP libraries that provide tools for tokenization, part-of-speech tagging, and other NLP tasks.\n",
      "*   **NumPy and Pandas:**  These libraries are essential for data manipulation and analysis.\n",
      "\n",
      "**III. Step-by-Step Guide to Building a Simple Language Model:**\n",
      "\n",
      "Here's a simplified example of building a character-level language model (predicting the next character in a sequence):\n",
      "\n",
      "1.  **Data Preparation:**\n",
      "    *   **Choose a dataset:**  Start with a relatively small text file (e.g., a novel, a collection of poems, or a script).\n",
      "    *   **Load the data:**  Read the text file into a string.\n",
      "    *   **Create a vocabulary:**  Identify all the unique characters in the text.\n",
      "    *   **Create character-to-index and index-to-character mappings:**  This will allow you to convert characters to numerical representations that the model can understand.\n",
      "    *   **Create sequences:**  Divide the text into sequences of a fixed length (e.g., 40 characters).  Each sequence will be an input to the model, and the next character after the sequence will be the target.\n",
      "\n",
      "    ```python\n",
      "    import numpy as np\n",
      "\n",
      "    # Load the data\n",
      "    text = open('your_text_file.txt', 'r').read().lower()\n",
      "\n",
      "    # Create vocabulary\n",
      "    chars = sorted(list(set(text)))\n",
      "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
      "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
      "\n",
      "    # Create sequences\n",
      "    seq_length = 40\n",
      "    step = 3\n",
      "    sentences = []\n",
      "    next_chars = []\n",
      "    for i in range(0, len(text) - seq_length, step):\n",
      "        sentences.append(text[i: i + seq_length])\n",
      "        next_chars.append(text[i + seq_length])\n",
      "\n",
      "    # Vectorize the data\n",
      "    x = np.zeros((len(sentences), seq_length, len(chars)), dtype=bool)\n",
      "    y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
      "    for i, sentence in enumerate(sentences):\n",
      "        for t, char in enumerate(sentence):\n",
      "            x[i, t, char_indices[char]] = 1\n",
      "        y[i, char_indices[next_chars[i]]] = 1\n",
      "    ```\n",
      "\n",
      "2.  **Model Building (using Keras with TensorFlow):**\n",
      "\n",
      "    ```python\n",
      "    from tensorflow.keras.models import Sequential\n",
      "    from tensorflow.keras.layers import LSTM, Dense, Activation\n",
      "\n",
      "    # Build the model\n",
      "    model = Sequential()\n",
      "    model.add(LSTM(128, input_shape=(seq_length, len(chars))))\n",
      "    model.add(Dense(len(chars)))\n",
      "    model.add(Activation('softmax'))\n",
      "\n",
      "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
      "    ```\n",
      "\n",
      "    *   **LSTM Layer:**  An LSTM (Long Short-Term Memory) layer is a type of recurrent neural network that is well-suited for processing sequential data.\n",
      "    *   **Dense Layer:**  A dense layer is a fully connected layer.\n",
      "    *   **Softmax Activation:**  The softmax activation function converts the output of the dense layer into a probability distribution over the characters.\n",
      "\n",
      "3.  **Training:**\n",
      "\n",
      "    ```python\n",
      "    # Train the model\n",
      "    model.fit(x, y, batch_size=128, epochs=20)\n",
      "    ```\n",
      "\n",
      "    *   **Batch Size:**  The number of sequences to process in each batch.\n",
      "    *   **Epochs:**  The number of times to iterate over the entire dataset.\n",
      "\n",
      "4.  **Text Generation:**\n",
      "\n",
      "    ```python\n",
      "    # Function to generate text\n",
      "    def sample(preds, temperature=1.0):\n",
      "        # helper function to sample an index from a probability array\n",
      "        preds = np.asarray(preds).astype('float64')\n",
      "        preds = np.log(preds) / temperature\n",
      "        exp_preds = np.exp(preds)\n",
      "        preds = exp_preds / np.sum(exp_preds)\n",
      "        probas = np.random.multinomial(1, preds, 1)\n",
      "        return np.argmax(probas)\n",
      "\n",
      "    def generate_text(length, temperature):\n",
      "        start_index = np.random.randint(0, len(text) - seq_length - 1)\n",
      "        generated = ''\n",
      "        sentence = text[start_index: start_index + seq_length]\n",
      "        generated += sentence\n",
      "        for i in range(length):\n",
      "            x_pred = np.zeros((1, seq_length, len(chars)))\n",
      "            for t, char in enumerate(sentence):\n",
      "                x_pred[0, t, char_indices[char]] = 1.\n",
      "\n",
      "            preds = model.predict(x_pred, verbose=0)[0]\n",
      "            next_index = sample(preds, temperature)\n",
      "            next_char = indices_char[next_index]\n",
      "\n",
      "            generated += next_char\n",
      "            sentence = sentence[1:] + next_char\n",
      "        return generated\n",
      "\n",
      "    # Generate text\n",
      "    print(generate_text(400, 0.5))\n",
      "    ```\n",
      "\n",
      "    *   **Temperature:**  A parameter that controls the randomness of the generated text.  A higher temperature will result in more random text, while a lower temperature will result in more predictable text.\n",
      "\n",
      "**IV.  Moving Towards More Advanced Models:**\n",
      "\n",
      "*   **Word-Level Models:** Instead of characters, use words as the basic unit. This requires more data and computational power but can produce more coherent text.\n",
      "*   **Embeddings:** Use pre-trained word embeddings (like Word2Vec, GloVe, or FastText) to represent words as vectors. This can significantly improve performance.\n",
      "*   **Transformers:**  Learn about the Transformer architecture and use the Hugging Face Transformers library to fine-tune pre-trained Transformer models (like BERT, GPT-2, or GPT-3) on your own data. This is the most common approach for building state-of-the-art language models.\n",
      "*   **Larger Datasets:**  The more data you have, the better your model will perform.\n",
      "*   **More Computational Resources:**  Training larger models requires more powerful hardware (GPUs or TPUs).\n",
      "\n",
      "**V. Challenges and Considerations:**\n",
      "\n",
      "*   **Data Acquisition and Cleaning:**  Finding and cleaning large datasets can be time-consuming and challenging.\n",
      "*   **Computational Resources:**  Training large language models requires significant computational resources.\n",
      "*   **Bias and Fairness:**  Language models can inherit biases from the data they are trained on.  It's important to be aware of these biases and take steps to mitigate them.\n",
      "*   **Ethical Considerations:**  Language models can be used for malicious purposes, such as generating fake news or spam.  It's important to use these models responsibly.\n",
      "\n",
      "**VI. Resources:**\n",
      "\n",
      "*   **Online Courses:** Coursera, edX, Udacity, and fast.ai offer courses on deep learning and NLP.\n",
      "*   **Books:** \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville; \"Natural Language Processing with Python\" by Steven Bird, Ewan Klein, and Edward Loper.\n",
      "*   **Tutorials:** The TensorFlow and PyTorch websites have excellent tutorials.  The Hugging Face Transformers documentation is also very helpful.\n",
      "*   **Research Papers:**  Read research papers on language modeling to stay up-to-date on the latest advances.\n",
      "\n",
      "**Important Notes:**\n",
      "\n",
      "*   **Start Small:** Don't try to build a massive model right away. Start with a small, simple model and gradually increase its complexity.\n",
      "*   **Experiment:**  Try different architectures, hyperparameters, and training techniques to see what works best.\n",
      "*   **Be Patient:**  Training language models can take a long time.\n",
      "*   **Learn from Others:**  Read blog posts, tutorials, and research papers to learn from the experiences of others.\n",
      "\n",
      "Building a language model is a challenging but rewarding project.  By following these steps and dedicating yourself to learning, you can gain a deep understanding of this fascinating field. Good luck!\n"
     ]
    }
   ],
   "source": [
    "print(output['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023607e",
   "metadata": {},
   "source": [
    "### Memory for Multi-turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d8d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c8583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e96d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11903d0a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# chat node\n",
    "def model_node(state):\n",
    "    summary = state.get(\"summary\",'')\n",
    "    if summary:\n",
    "        system_message = f\"Summmary of previous chat : {summary}\"\n",
    "        messages = [SystemMessage(system_message)] + state['messages']\n",
    "    else:\n",
    "        messages = state['messages']\n",
    "        \n",
    "    return {'messages': [llm.invoke(messages)]}\n",
    "\n",
    "# Summaraize node\n",
    "def summary_node(state):\n",
    "    summarize_prompt = [HumanMessage('Summarize the whole chat until now , so it can be used as chat history, only generate summary nothing else')]\n",
    "    history_chat = state['messages']\n",
    "    model_input_for_summary = history_chat + summarize_prompt\n",
    "    return {\"summary\": llm.invoke(model_input_for_summary)}\n",
    "\n",
    "def condition(state):\n",
    "    if len(state['messages']) > 4:\n",
    "        return \"summary_node\"\n",
    "    else:\n",
    "        return END \n",
    "\n",
    "# Graph nodes and connections\n",
    "graph.add_node('model_node', model_node)\n",
    "graph.add_node(summary_node)\n",
    "\n",
    "graph.add_edge(START, 'model_node')\n",
    "graph.add_conditional_edges('model_node', condition)\n",
    "\n",
    "graph.add_edge('summary_node', END)\n",
    "\n",
    "# Compile graph\n",
    "graph = graph.compile(checkpointer=memory)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e9c5ae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StateGraph' object has no attribute 'get_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m()\u001b[38;5;241m.\u001b[39mdraw_mermaid_png()))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StateGraph' object has no attribute 'get_graph'"
     ]
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a22872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}, id='74b1c451-f79b-478a-b022-96c35600d85c'),\n",
       "  AIMessage(content='I am a large language model, trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--14017446-d838-416d-bd06-5ea3a643e05e-0', usage_metadata={'input_tokens': 3, 'output_tokens': 12, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofig = {'configurable': {'thread_id':1}}\n",
    "graph.invoke({'messages': {'role':'user','content':'who are you'}},config=cofig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1acc6a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}, id='74b1c451-f79b-478a-b022-96c35600d85c'),\n",
       "  AIMessage(content='I am a large language model, trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--14017446-d838-416d-bd06-5ea3a643e05e-0', usage_metadata={'input_tokens': 3, 'output_tokens': 12, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='who built you', additional_kwargs={}, response_metadata={}, id='8cf88c0e-1593-48c5-9377-fac687557722'),\n",
       "  AIMessage(content='I was trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--cd1cf627-fff0-4cbd-88cb-56de8e7ec093-0', usage_metadata={'input_tokens': 17, 'output_tokens': 7, 'total_tokens': 24, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'messages' : [HumanMessage('who built you')]},config=cofig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24d63b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8a43f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4595c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6957f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f12aa336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e8262bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! It's nice to meet you. How can I help you today?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Lance. You just told me! 😊\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's awesome! They're a great team. What do you like most about the 49ers? Are you excited for the upcoming season?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"i like the 49ers!\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe7d42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='5e84b096-59a1-4f62-b253-f57a07682900'), AIMessage(content=\"Hi Lance! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--9d96b000-d7f6-43e0-9898-9c230cbc9f7e-0', usage_metadata={'input_tokens': 6, 'output_tokens': 19, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}}), HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='bdef8595-03ef-4416-9dff-3f8697290f9f'), AIMessage(content='Your name is Lance. You just told me! 😊', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--b39318ef-fcf5-4041-a0fb-300de46b95b2-0', usage_metadata={'input_tokens': 30, 'output_tokens': 12, 'total_tokens': 42, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='i like the 49ers!', additional_kwargs={}, response_metadata={}, id='dc4331d9-6377-4d63-9d42-103a3de1b73a'), AIMessage(content=\"That's awesome! They're a great team. What do you like most about the 49ers? Are you excited for the upcoming season?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--dc425dba-c8f2-46ed-a2b3-cfde904b8afe-0', usage_metadata={'input_tokens': 49, 'output_tokens': 33, 'total_tokens': 82, 'input_token_details': {'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f02af68-7089-6612-8007-5d270b82a73c'}}, metadata={'source': 'loop', 'writes': {'conversation': {'messages': AIMessage(content=\"That's awesome! They're a great team. What do you like most about the 49ers? Are you excited for the upcoming season?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--dc425dba-c8f2-46ed-a2b3-cfde904b8afe-0', usage_metadata={'input_tokens': 49, 'output_tokens': 33, 'total_tokens': 82, 'input_token_details': {'cache_read': 0}})}}, 'step': 7, 'parents': {}, 'thread_id': '1'}, created_at='2025-05-07T03:51:16.429320+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f02af68-63b9-66c6-8006-e3107ef01965'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45627c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "278a9734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You're right, Nick Bosa is a fantastic player! And yes, he is currently the highest-paid defensive player in the NFL. He signed a massive contract extension that made him the highest-paid at his position. He's definitely a key part of the 49ers' success.\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"i like Nick Bosa, isn't he the highest paid defensive player?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e69eb3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, here's a summary of our conversation:\\n\\nLance introduced himself. I acknowledged him and asked how I could help. He then asked me what his name was, and I reminded him that he had just told me it was Lance. He then stated he likes the 49ers, and I responded positively, asking what he liked about them and if he was excited for the season. He replied that he likes Nick Bosa and asked if he was the highest-paid defensive player, to which I confirmed that he is.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9034a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4f8cc91",
   "metadata": {},
   "source": [
    "### simple web rag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff573029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b896888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    context:Annotated[list, operator.add]\n",
    "    \n",
    "graph = StateGraph(State)\n",
    "\n",
    "# Nodes\n",
    "def duckduckgo_search(state):\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    question = state['question']\n",
    "    search_result = search.invoke(question)\n",
    "    return {'context': [search_result]}\n",
    "\n",
    "def wiki_search(state):\n",
    "    question = state['question']\n",
    "    documents = WikipediaLoader(question, load_max_docs=5).load()\n",
    "    search_result = []\n",
    "    for doc in documents:\n",
    "        search_result.append(doc.metadata['summary'])\n",
    "    \n",
    "    return {'context':  search_result}\n",
    "\n",
    "def model_call(state):\n",
    "    context = '\\n'.join(state['context'])\n",
    "    prompt = (f\"context: {context}\\n Answer the question: {state['question']} using the context above, if the answer does not present in the context say it\")\n",
    "    return {'answer': model.invoke(prompt)}\n",
    "\n",
    "graph.add_node('wiki', wiki_search)\n",
    "graph.add_node('duck',duckduckgo_search)\n",
    "graph.add_node('model', model_call)\n",
    "\n",
    "graph.add_edge(START, 'wiki')\n",
    "graph.add_edge(START, 'duck')\n",
    "graph.add_edge('wiki', 'model')\n",
    "graph.add_edge('duck','model')\n",
    "graph.add_edge('model',END)\n",
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f36509e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mtimeout\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/urllib3/util/retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py:367\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/langchain_core/runnables/graph_mermaid.py:430\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[0;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m requests\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mok:\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/requests/adapters.py:713\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/langchain_core/runnables/graph.py:685\u001b[0m, in \u001b[0;36mGraph.draw_mermaid_png\u001b[0;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[1;32m    679\u001b[0m mermaid_syntax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_mermaid(\n\u001b[1;32m    680\u001b[0m     curve_style\u001b[38;5;241m=\u001b[39mcurve_style,\n\u001b[1;32m    681\u001b[0m     node_colors\u001b[38;5;241m=\u001b[39mnode_colors,\n\u001b[1;32m    682\u001b[0m     wrap_label_n_words\u001b[38;5;241m=\u001b[39mwrap_label_n_words,\n\u001b[1;32m    683\u001b[0m     frontmatter_config\u001b[38;5;241m=\u001b[39mfrontmatter_config,\n\u001b[1;32m    684\u001b[0m )\n\u001b[0;32m--> 685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/langchain_core/runnables/graph_mermaid.py:293\u001b[0m, in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    287\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    288\u001b[0m         _render_mermaid_using_pyppeteer(\n\u001b[1;32m    289\u001b[0m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[1;32m    290\u001b[0m         )\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m draw_method \u001b[38;5;241m==\u001b[39m MermaidDrawMethod\u001b[38;5;241m.\u001b[39mAPI:\n\u001b[0;32m--> 293\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     supported_methods \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "File \u001b[0;32m~/AI/PROJECTS/Simple-Multi-turn-ChatBot-with-langgraph/.venv/lib/python3.9/site-packages/langchain_core/runnables/graph_mermaid.py:462\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[0;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    459\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m retries. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m             ) \u001b[38;5;241m+\u001b[39m error_msg_suffix\n\u001b[0;32m--> 462\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# This should not be reached, but just in case\u001b[39;00m\n\u001b[1;32m    465\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m retries. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m ) \u001b[38;5;241m+\u001b[39m error_msg_suffix\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b17a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({'question':'what are the recent problem with india and pakistan'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a01b318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The escalating conflict between India and Pakistan, two neighbors who have been rivals for decades, erupted in the early hours of Wednesday morning when New Delhi launched missiles across the border. New Delhi said its strikes on Pakistan were both a response to last month's attack that killed at least 26 people Indian-administered Kashmir and a deterrent against future attacks, which India ... India launched military strikes on targets in Pakistan, both countries said on Wednesday and Pakistan claimed it had shot down five Indian Air Force jets, in an escalation that has pushed the two ... The conflict between India and Pakistan puts two of the world's nuclear powers head to head. ... Pakistan may also have reason to respond with more force to India's recent attack than in the past. Turkish President Recip Tayyip Erdogan has spoken with Pakistan's Prime Minister Shehbaz Sharif on a call to convey his solidarity after India hit Pakistan and Pakistani Kashmir with missiles.The partition of India in 1947 was the division of British India into two independent dominion states, the Union of India and Dominion of Pakistan. The Union of India is today the Republic of India and the Dominion of Pakistan, the Islamic Republic of Pakistan, and the People's Republic of Bangladesh. The partition involved the division of two provinces, Bengal and the Punjab, based on district-wise Hindu or Muslim majorities. It also involved the division of the British Indian Army, the Royal Indian Navy, the Indian Civil Service, the railways, and the central treasury, between the two new dominions. The partition was set forth in the Indian Independence Act 1947 and resulted in the dissolution of the British Raj, or Crown rule in India. The two self-governing countries of India and Pakistan legally came into existence at midnight on 14–15 August 1947.\n",
      "The partition displaced between 12 and 20 million people along religious lines, creating overwhelming refugee crises in the newly constituted dominions; there was large-scale violence, with estimates of loss of life accompanying or preceding the partition disputed and varying between several hundred thousand and two million. The violent nature of the partition created an atmosphere of hostility and suspicion between India and Pakistan that plagues their relationship to the present.\n",
      "The term partition of India does not cover the secession of Bangladesh from Pakistan in 1971, nor the earlier separations of Burma (now Myanmar) and Ceylon (now Sri Lanka) from the administration of British India. The term also does not cover the political integration of princely states into the two new dominions, nor the disputes of annexation or division arising in the princely states of Hyderabad, Junagadh, and Jammu and Kashmir, though violence along religious lines did break out in some princely states at the time of the partition.  It does not cover the incorporation of the enclaves of French India into India during the period 1947–1954, nor the annexation of Goa and other districts of Portuguese India by India in 1961. Other contemporaneous political entities in the region in 1947, such as Sikkim, Bhutan, Nepal, and the Maldives, were unaffected by the partition.Kashmir ( KASH-meer or  kash-MEER) is the northernmost geographical region of the Indian subcontinent. Until the mid-19th century, the term Kashmir denoted only the Kashmir Valley between the Great Himalayas and the Pir Panjal Range. The term has since also come to encompass a larger area that includes the India-administered territories of Jammu and Kashmir and Ladakh, the Pakistan-administered territories of Azad Kashmir and Gilgit-Baltistan, and the Chinese-administered territories of Aksai Chin and the Trans-Karakoram Tract.\n",
      "\n",
      "In 1820, the Sikh Empire, under Ranjit Singh, annexed Kashmir. In 1846, after the Sikh defeat in the First Anglo-Sikh War, and upon the purchase of the region from the British under the Treaty of Amritsar, the Raja of Jammu, Gulab Singh, became the new ruler of Kashmir. The rule of his descendants, under the paramountcy (or tutelage) of the British Crown, lasted until the Partition of India in 1947, when the former princely state of the British Indian Empire became a disputed territory, now administered by three countries: China, India, and Pakistan.\n",
      "\n",
      "The Kashmir conflict is a territorial conflict over the Kashmir region, primarily between India and Pakistan, and also between China and India in the northeastern portion of the region. The conflict started after the partition of India in 1947 as both India and Pakistan claimed the entirety of the former princely state of Jammu and Kashmir. It is a dispute over the region that escalated into three wars between India and Pakistan and several other armed skirmishes. India controls approximately 55% of the land area of the region that includes Jammu, the Kashmir Valley, most of Ladakh, the Siachen Glacier, and 70% of its population; Pakistan controls approximately 30% of the land area that includes Azad Kashmir and Gilgit-Baltistan; and China controls the remaining 15% of the land area that includes the Aksai Chin region, the mostly uninhabited Trans-Karakoram Tract, and part of the Demchok sector.\n",
      "After the partition of India and a rebellion in the western districts of the state, Pakistani tribal militias invaded Kashmir, leading the Hindu ruler of Jammu and Kashmir to join India. The resulting Indo-Pakistani War ended with a UN-mediated ceasefire along a line that was eventually named the Line of Control. In 1962, China invaded and fought a war with India along the disputed Indo-Chinese border, including in Indian administered-Ladakh, marking their entry to the Kashmir conflict. In 1965, Pakistan attempted to infiltrate Indian-administered Kashmir to precipitate an insurgency there, resulting in another war fought by the two countries over the region. After further fighting during the war of 1971, the Simla Agreement formally established the Line of Control between the territories under Indian and Pakistani control. In 1999, an armed conflict between the two countries broke out again in Kargil with no effect on the status quo.\n",
      "In 1989, an armed insurgency erupted against Indian rule in Indian-administered Kashmir Valley, after years of political disenfranchisement and alienation, with logistical support from Pakistan. The insurgency was actively opposed in Jammu and Ladakh, where it revived long-held demands for autonomy from Kashmiri dominance and greater integration with India. Spearheaded by a group seeking creation of an independent state based on demands for self-determination, the insurgency was taken over within the first few years of its outbreak by Pakistan-backed Jihadist groups striving for merger with Pakistan. The militancy continued through the 1990s and early 2000s—by which time it was being driven largely by foreign militants and spread to parts of the adjoining Jammu region—but declined thereafter.  The fighting resulted in tens of thousands of casualties, both combatant and civilian. The militancy also resulted in the exodus of Kashmiri Hindus from the predominantly Muslim Kashmir Valley in the early 1990s. Counterinsurgency by the Indian government was coupled with repression of the local population and increased militarisation of the region, while various insurgent groups engaged in a variety of criminal activity. The 2010s were marked by civil unrest within the Kashmir Valley, fuelled by unyielding militarisation, rights violations, mis-rule and corruption, wherein protesting local youths violently clashed with Indian security forces, with large-scale demonstrations taking place during the 2010 unrest triggered by an allegedly staged encounter, and during the 2016 unrest which ensued after the killing of a young militant from a Jihadist group, who had risen to popularity through social media. Further unrest in the region erupted after the 2019 Pulwama attack.\n",
      "According to scholars, Indian forces have committed many human rights abuses and acts of terror against the Kashmiri civilian population, including extrajudicial killing, rape, torture, and enforced disappearances. According to Amnesty International, no member of the Indian military deployed in Jammu and Kashmir has been tried for human rights violations in a civilian court as of June 2015, although military courts-martial have been held. Amnesty International has also accused the Indian government of refusing to prosecute perpetrators of abuses in the region. Moreover, there have been instances of human rights abuses in Azad Kashmir, including but not limited to political repressions and forced disappearances. Brad Adams, the Asia director at Human Rights Watch said in 2006 \"Although 'Azad' means 'free', the residents of Azad Kashmir are anything but free. The Pakistani authorities govern Azad Kashmir with strict controls on basic freedoms\". The OHCHR reports on Kashmir released two reports on \"the situation of human rights in Indian-Administered Kashmir and Pakistan-Administered Kashmir\".Pakistan is one of nine states that possess nuclear weapons. Pakistan began developing nuclear weapons in January 1972 under Prime Minister Zulfikar Ali Bhutto, who delegated the program to the Chairman of the Pakistan Atomic Energy Commission (PAEC) Munir Ahmad Khan with a commitment to having the device ready by the end of 1976. Since PAEC, which consisted of over twenty laboratories and projects under reactor physicist Munir Ahmad Khan, was falling behind schedule and having considerable difficulty producing fissile material, Abdul Qadeer Khan, a metallurgist working on centrifuge enrichment for Urenco, joined the program at the behest of the Bhutto administration by the end of 1974. Producing fissile material was pivotal to the Kahuta Project's success and thus to Pakistan obtaining the capability to detonate a nuclear weapon by the end of 1984.\n",
      "The Kahuta Project started under the supervision of a coordination board that oversaw the activities of KRL and PAEC. The Board consisted of A G N Kazi (secretary general, finance), Ghulam Ishaq Khan (secretary general, defence), and Agha Shahi (secretary general, foreign affairs), and reported directly to Bhutto. Ghulam Ishaq Khan and General Tikka Khan appointed Major General Ali Nawab as the ranking engineer on the program. Moderate uranium enrichment for the production of fissile material was achieved at KRL by April 1978. Eventually, the supervision passed to Lt General Zahid Ali Akbar Khan in President General Muhammad Zia-ul-Haq's administration.\n",
      "Pakistan's nuclear weapons development was in response to the loss of East Pakistan in 1971's Bangladesh Liberation War. Bhutto called a meeting of senior scientists and engineers on 20 January 1972. Bhutto was the main architect of this programme, and it was here that Bhutto orchestrated the nuclear weapons programme and rallied Pakistan's academic scientists to build an atomic bomb in three years for national survival.\n",
      "At the meeting, Bhutto also appointed Munir Ahmad Khan as chairman of PAEC, who, until then, had been working as director at the nuclear power and Reactor Division of the International Atomic Energy Agency (IAEA), in Vienna, Austria. In December 1972, Abdus Salam led the establishment of Theoretical Physics Group (TPG) as he called scientists working at ICTP to report to Munir Ahmad Khan. This marked the beginning of Pakistan's pursuit of nuclear deterrence capability. Following India's surprise nuclear test, codenamed Smiling Buddha in 1974, the first confirmed nuclear test by a nation outside the permanent five members of the United Nations Security Council, the goal to develop nuclear weapons received considerable impetus.\n",
      "Finally, on 28 May 1998, a few weeks after India's second nuclear test (Operation Shakti), Pakistan detonated five nuclear devices in the Ras Koh Hills in the Chagai district, Balochistan. This operation was named Chagai-I by Pakistan, the underground iron-steel tunnel having been long-constructed by provincial martial law administrator General Rahimuddin Khan during the 1980s. The Pakistani Atomic Energy Commission reported that the five nuclear tests conducted on May 28 generated a seismic signal of 5.0 on the Richter scale, with a total yield of up to 40 KT (equivalent TNT). Dr. A.Q. Khan claimed that one device was a boosted fission device and that the other four were sub-kiloton nuclear devices. The last test of Pakistan was conducted at the sandy Kharan Desert under the codename Chagai-II, also in Balochistan, on 30 May 1998. Pakistan's fissile material production takes place at Nilore, Kahuta, and Khushab Nuclear Complex, where weapons-grade plutonium is refined. Pakistan thus became the seventh country in the world to successfully develop and test nuclear weapons, although according to a letter sent by A.Q. Khan to General Zia, the capability to detonate a nuclear bomb using highly enriched uranium as fissile material produced at KRL had already been achieved by KRL in 1984.The Indo-Pakistani war of 1965, also known as  the second Indo–Pakistani war, was an armed conflict between Pakistan and India that took place from August 1965 to September 1965. The conflict began following Pakistan's unsuccessful Operation Gibraltar, which was designed to infiltrate forces into Jammu and Kashmir to precipitate an insurgency against Indian rule. The seventeen day war caused thousands of casualties on both sides and witnessed the largest engagement of armoured vehicles and the largest tank battle since World War II. Hostilities between the two countries ended after a ceasefire was declared through UNSC Resolution 211 following a diplomatic intervention by the Soviet Union and the United States, and the subsequent issuance of the Tashkent Declaration. Much of the war was fought by the countries' land forces in Kashmir and along the border between India and Pakistan. This war saw the largest amassing of troops in Kashmir since the Partition of India in 1947, a number that was overshadowed only during the 2001–2002 military standoff between India and Pakistan. Most of the battles were fought by opposing infantry and armoured units, with substantial backing from air forces, and naval operations.\n",
      "India had the upper hand over Pakistan when the ceasefire was declared. However, in terms of aerial warfare, the PAF managed an upper hand over the combat zones despite being numerically inferior. Although the two countries fought to a standoff, the conflict is seen as a strategic and political defeat for Pakistan, as it had not succeeded in fomenting an insurrection in Kashmir and was instead forced to shift gears in the defence of Lahore. India also failed to achieve its objective of military deterrence and did not capitalise on its advantageous military situation before the ceasefire was declared.\n",
      "Internationally, the war was viewed in the context of the greater Cold War, and resulted in a significant geopolitical shift in the subcontinent. Before the war, the United States and the United Kingdom had been major material allies of both India and Pakistan, as their primary suppliers of military hardware and foreign developmental aid. During and after the conflict, both India and Pakistan felt betrayed by the perceived lack of support by the western powers for their respective positions; those feelings of betrayal were increased with the imposition of an American and British embargo on military aid to the opposing sides. As a consequence, India and Pakistan openly developed closer relationships with the Soviet Union and China, respectively. The perceived negative stance of the western powers during the conflict, and during the 1971 war, has continued to affect relations between the West and the subcontinent. Despite improved relations with the US and Britain since the end of the Cold War, the conflict generated a deep distrust of both countries within the subcontinent which, to an extent, still lingers today.\n"
     ]
    }
   ],
   "source": [
    "print(''.join(result['context']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45691074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The core problem between India and Pakistan is a complex and multifaceted dispute rooted in historical events, political tensions, and territorial claims. Here's a breakdown of the key issues:\n",
      "\n",
      "*   **The Partition of British India (1947):** The division of British India into India and Pakistan led to mass displacement, violence, and lasting animosity. The partition created a legacy of mistrust and unresolved issues.\n",
      "\n",
      "*   **Territorial Disputes, Especially Kashmir:** The primary point of contention is the region of Jammu and Kashmir. Both countries claim the territory, leading to multiple wars and ongoing conflict. The region is divided, with India, Pakistan, and China controlling different portions.\n",
      "\n",
      "*   **Cross-Border Terrorism and Alleged Subversive Acts:** India accuses Pakistan of sponsoring cross-border terrorism, while Pakistan alleges subversive acts by India. These accusations fuel further distrust and hinder efforts to improve relations.\n",
      "\n",
      "*   **Religious Differences:** While both countries have diverse populations, the creation of India as a secular republic with a Hindu majority and Pakistan as an Islamic republic with a Muslim majority has contributed to communal tensions and mistrust.\n",
      "\n",
      "*   **Lack of Political Will:** The text suggests that neither side sees significant political advantages in pursuing better relations, leading to a state of \"minimalist engagement\" and a \"cold peace.\"\n",
      "\n",
      "In the context of the provided text, the 2025 Pahalgam attack and the subsequent escalation (diplomatic crisis, military strikes) are the latest manifestation of this long-standing problem.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0817e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "question = 'algebra'\n",
    "search_result = search.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00e20664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Algebra is a branch of mathematics that studies abstract systems and operations. Learn about its origin, development, and major branches, such as elementary, linear, and abstract algebra. Learn about the origin and evolution of algebra, the branch of mathematics that manipulates abstract symbols rather than numbers. Explore the ancient and modern developments of equations, number systems, and symbolic language in algebra. Algebra did not always make use of the symbolism that is now ubiquitous in mathematics; instead, it went through three distinct stages. The stages in the development of symbolic algebra are approximately as follows: [3] Rhetorical algebra, in which equations are written in full sentences. For example, the rhetorical form of x + 1 = 2 {\\\\displaystyle x+1=2} is \"The thing plus one equals two\" or ... Learn the basics of algebra, including expressions, equations, operations, and methods for solving linear and quadratic equations. Explore algebra formulas, tricks, practice questions, and coding solutions for programmers. Learn the fundamentals of algebra, such as variables, expressions, equations, and operations. Find examples of linear, quadratic, and cubic equations, and how to solve them using algebraic rules and methods.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a91dc5",
   "metadata": {},
   "source": [
    "### hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52963d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyst(BaseModel):\n",
    "    affiliation:str = Field(description='Primary Affiliation of the analyst')\n",
    "    name: str = Field(description='name of the analyst')\n",
    "    role: str = Field(description='role of the analyst in the context of the topic')\n",
    "    description:str = Field(description='description of the analyst focus, concerns and motives')\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "    \n",
    "class Perspective(BaseModel):\n",
    "    analysts: List[Analyst] = Field(description='Comprehensive list of analyst with their roles and affiliatoins')\n",
    "    \n",
    "class GeneralAnalystState(TypedDict):\n",
    "    topic: str\n",
    "    max_analyst: str\n",
    "    human_analyst_feedback: str\n",
    "    analysts: List[Analyst]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b0f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "analyst_instructions = \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
    "\n",
    "1. First, review the research topic:\n",
    "{topic}\n",
    "\n",
    "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
    "{human_analyst_feedback}\n",
    "\n",
    "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
    "\n",
    "4. Pick the top {max_analysts} themes.\n",
    "\n",
    "5. Assign one analyst to each theme.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5b3f05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x115667160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node\n",
    "def create_analysts(state: GeneralAnalystState):\n",
    "    topic = state['topic']\n",
    "    max_analyst = state['max_analyst']\n",
    "    human_analyst_feedback = state.get('human_analyst_feedback','')\n",
    "    structured_model = model.with_structured_output(Perspective)\n",
    "    system_message = analyst_instructions.format(topic=topic,\n",
    "                                                human_analyst_feedback=human_analyst_feedback,\n",
    "                                                max_analyst=max_analyst)\n",
    "    message = [SystemMessage(analyst_instructions),\n",
    "               HumanMessage('Generate a set of Analyst')]\n",
    "    output = structured_model.invoke(message)\n",
    "    return {'analysts':output.analysts}\n",
    "\n",
    "def human_feedback(state: GeneralAnalystState):\n",
    "    pass\n",
    "\n",
    "def should_continue(state: GeneralAnalystState):\n",
    "    human_analyst_feedback = state.get('human_analyst_feedback', None)\n",
    "    if human_analyst_feedback:\n",
    "        return 'create_analyst'    \n",
    "    return END\n",
    "    \n",
    "\n",
    "\n",
    "builder = StateGraph(GeneralAnalystState)\n",
    "\n",
    "builder.add_node('create_analysts', create_analysts)\n",
    "builder.add_node('human_feedback', human_feedback)\n",
    "builder.add_edge(START, 'create_analysts')\n",
    "builder.add_edge('create_analysts', 'human_feedback')\n",
    "builder.add_conditional_edges(\n",
    "    'human_feedback',\n",
    "    should_continue,\n",
    "    ['create_analysts', END]\n",
    ")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory, interrupt_before=['human_feedback'])\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1518dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73703756",
   "metadata": {},
   "outputs": [],
   "source": [
    "pers = model.with_structured_output(Perspective).invoke('Generate a set of analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef859767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Analyst(affiliation='ThinkTankA', name='John Smith', role='National Security Analyst', description='Cybersecurity threats from a national security perspective'),\n",
       " Analyst(affiliation='BankOfAmerica', name='Jane Doe', role='Financial Analyst', description='Cybersecurity threats from a financial perspective')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pers.analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b6922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

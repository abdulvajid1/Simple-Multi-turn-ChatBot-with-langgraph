{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c87ce03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langgraph.graph.message import AnyMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages, MessagesState\n",
    "from typing import Annotated\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "import operator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a50c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86fde65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73d5b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23919a3",
   "metadata": {},
   "source": [
    "### Simple Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "343aabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "562f7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65f89f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b710b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77495135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2d9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_call_node(state):\n",
    "    return {\"messages\" : [llm.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947056a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x106428f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.set_entry_point('node1')\n",
    "graph.add_node('node1', model_call_node)\n",
    "graph.add_edge('node1', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bde526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57fe7c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langgraph.graph.state.CompiledStateGraph"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "011ebb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage('can you explain me how you get build')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c409c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.invoke({'messages': messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f9820da",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_message = [HumanMessage('ok now explain me how can i do it')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53da8b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='can you explain me how you get build', additional_kwargs={}, response_metadata={}, id='5b0d0c99-a94b-45e0-9252-58bb8567fef8'),\n",
       " AIMessage(content='Okay, let\\'s break down how I, as a large language model, am \"built.\" It\\'s a multi-faceted process involving data, architecture, training, and ongoing refinement.  Think of it like building a house: you need materials (data), a blueprint (architecture), construction workers (training algorithms), and ongoing maintenance (refinement).\\n\\n**1. Data: The Foundation**\\n\\n*   **Massive Text and Code Datasets:** I am trained on an enormous amount of text and code data. This data comes from a variety of sources, including:\\n    *   **The Internet:**  Web pages, articles, blog posts, forums, and other publicly available text.\\n    *   **Books:**  A vast collection of published books.\\n    *   **Code Repositories:**  Code from platforms like GitHub, covering many programming languages.\\n    *   **Other Sources:**  Scientific papers, news articles, and other specialized datasets.\\n*   **Data Cleaning and Preprocessing:** The raw data is often messy and needs to be cleaned and preprocessed. This involves:\\n    *   **Removing irrelevant content:**  Filtering out noise, advertisements, and low-quality text.\\n    *   **Tokenization:**  Breaking down the text into smaller units called \"tokens\" (usually words or parts of words).\\n    *   **Normalization:**  Converting text to a consistent format (e.g., lowercase, removing punctuation).\\n    *   **Data Augmentation:**  Sometimes, the data is augmented to increase its diversity and improve the model\\'s robustness.\\n\\n**2. Architecture: The Blueprint**\\n\\n*   **Transformer Networks:**  The core architecture used in most modern large language models, including me, is based on the \"Transformer\" neural network architecture.\\n*   **Key Components of the Transformer:**\\n    *   **Attention Mechanism:**  This is the heart of the Transformer. It allows the model to focus on the most relevant parts of the input when processing it.  Instead of treating all words equally, the attention mechanism assigns weights to different words based on their importance in the context.\\n    *   **Encoder:**  Processes the input sequence and creates a representation of it.\\n    *   **Decoder:**  Generates the output sequence based on the encoded representation.\\n    *   **Multi-Head Attention:**  The attention mechanism is applied multiple times in parallel (\"multiple heads\") to capture different aspects of the input.\\n    *   **Feedforward Neural Networks:**  After the attention layers, feedforward neural networks are used to further process the information.\\n    *   **Residual Connections and Layer Normalization:**  These techniques help to stabilize training and improve performance.\\n*   **Scaling Up:**  Large language models are characterized by their massive size, often with billions or even trillions of parameters (the weights and biases in the neural network).  The more parameters, the more complex patterns the model can learn.\\n\\n**3. Training: The Construction Process**\\n\\n*   **Self-Supervised Learning:**  I am trained using a technique called \"self-supervised learning.\" This means that the model learns from the data itself, without explicit labels.\\n*   **Training Objectives:**  Common training objectives include:\\n    *   **Language Modeling:**  Predicting the next word in a sequence.  The model is given a sequence of words and asked to predict the word that comes next. This forces the model to learn the statistical relationships between words and phrases.\\n    *   **Masked Language Modeling (MLM):**  Randomly masking some of the words in a sequence and asking the model to predict the masked words.  This helps the model to understand the context of words and their relationships to each other.\\n    *   **Next Sentence Prediction (NSP):**  Given two sentences, predicting whether the second sentence follows the first.  This helps the model to understand the relationships between sentences and paragraphs.\\n*   **Optimization:**  The model\\'s parameters are adjusted during training to minimize the loss function (the difference between the model\\'s predictions and the actual values).  This is done using optimization algorithms like stochastic gradient descent (SGD) or Adam.\\n*   **Distributed Training:**  Training large language models requires massive computational resources.  The training process is typically distributed across many GPUs or TPUs (Tensor Processing Units) to speed it up.\\n\\n**4. Refinement: Ongoing Maintenance and Improvement**\\n\\n*   **Fine-Tuning:**  After the initial pre-training, the model can be fine-tuned on specific tasks or datasets.  This involves training the model on a smaller, more focused dataset to improve its performance on a particular task.  For example, a language model could be fine-tuned for question answering, text summarization, or machine translation.\\n*   **Reinforcement Learning from Human Feedback (RLHF):**  This is a technique used to align the model\\'s behavior with human preferences.  Human evaluators provide feedback on the model\\'s responses, and this feedback is used to train a reward model.  The reward model is then used to train the language model using reinforcement learning.\\n*   **Continuous Learning:**  The model is continuously updated with new data and improved training techniques.  This helps to keep the model up-to-date and improve its performance over time.\\n*   **Safety and Bias Mitigation:**  Efforts are made to mitigate biases in the model and ensure that it is used responsibly.  This involves carefully curating the training data, developing techniques to detect and remove biases, and implementing safety mechanisms to prevent the model from generating harmful or offensive content.\\n\\n**In Summary:**\\n\\nI am \"built\" through a complex process of:\\n\\n1.  **Gathering and preparing massive amounts of text and code data.**\\n2.  **Designing a powerful neural network architecture (Transformer).**\\n3.  **Training the model on the data using self-supervised learning.**\\n4.  **Refining the model through fine-tuning, reinforcement learning, and continuous learning.**\\n\\nThis process requires significant computational resources, expertise in machine learning, and ongoing research and development.  The field is constantly evolving, and new techniques are being developed to improve the performance, safety, and efficiency of large language models.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--6cc66ebe-6893-45fd-86c7-8a62dfb14aea-0', usage_metadata={'input_tokens': 8, 'output_tokens': 1300, 'total_tokens': 1308, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content='ok now explain me how can i do it', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state['messages'] + new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89487c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = graph.invoke({'messages': state['messages'] + new_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eee5740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down how you can build your own language model. Be warned: building a *large* language model like me requires significant resources and expertise. However, you can definitely build smaller, simpler models to learn the concepts and gain practical experience. Here's a roadmap:\n",
      "\n",
      "**I. Foundational Knowledge:**\n",
      "\n",
      "*   **Programming:**  Python is the dominant language for machine learning.  You'll need to be comfortable with Python syntax, data structures, and libraries.\n",
      "*   **Linear Algebra and Calculus:**  A basic understanding of these mathematical concepts is essential for understanding how neural networks work.\n",
      "*   **Machine Learning Fundamentals:**  Learn the basics of machine learning, including:\n",
      "    *   Supervised vs. Unsupervised Learning\n",
      "    *   Neural Networks (especially feedforward networks)\n",
      "    *   Backpropagation\n",
      "    *   Optimization algorithms (e.g., Gradient Descent, Adam)\n",
      "    *   Evaluation metrics (e.g., accuracy, precision, recall)\n",
      "*   **Natural Language Processing (NLP) Fundamentals:**  Learn the basics of NLP, including:\n",
      "    *   Tokenization\n",
      "    *   Word Embeddings (e.g., Word2Vec, GloVe)\n",
      "    *   Recurrent Neural Networks (RNNs) and LSTMs (though Transformers are now more common)\n",
      "    *   Sequence-to-Sequence models\n",
      "\n",
      "**II. Tools and Libraries:**\n",
      "\n",
      "*   **TensorFlow or PyTorch:** These are the two most popular deep learning frameworks.  Choose one and become proficient in it.  PyTorch is often considered more beginner-friendly, but TensorFlow has a larger ecosystem.\n",
      "*   **Hugging Face Transformers:** This library provides pre-trained models and tools for working with Transformers.  It's a great way to get started quickly.\n",
      "*   **NLTK or spaCy:** These are NLP libraries that provide tools for tokenization, part-of-speech tagging, and other NLP tasks.\n",
      "*   **NumPy and Pandas:**  These libraries are essential for data manipulation and analysis.\n",
      "\n",
      "**III. Step-by-Step Guide to Building a Simple Language Model:**\n",
      "\n",
      "Here's a simplified example of building a character-level language model (predicting the next character in a sequence):\n",
      "\n",
      "1.  **Data Preparation:**\n",
      "    *   **Choose a dataset:**  Start with a relatively small text file (e.g., a novel, a collection of poems, or a script).\n",
      "    *   **Load the data:**  Read the text file into a string.\n",
      "    *   **Create a vocabulary:**  Identify all the unique characters in the text.\n",
      "    *   **Create character-to-index and index-to-character mappings:**  This will allow you to convert characters to numerical representations that the model can understand.\n",
      "    *   **Create sequences:**  Divide the text into sequences of a fixed length (e.g., 40 characters).  Each sequence will be an input to the model, and the next character after the sequence will be the target.\n",
      "\n",
      "    ```python\n",
      "    import numpy as np\n",
      "\n",
      "    # Load the data\n",
      "    text = open('your_text_file.txt', 'r').read().lower()\n",
      "\n",
      "    # Create vocabulary\n",
      "    chars = sorted(list(set(text)))\n",
      "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
      "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
      "\n",
      "    # Create sequences\n",
      "    seq_length = 40\n",
      "    step = 3\n",
      "    sentences = []\n",
      "    next_chars = []\n",
      "    for i in range(0, len(text) - seq_length, step):\n",
      "        sentences.append(text[i: i + seq_length])\n",
      "        next_chars.append(text[i + seq_length])\n",
      "\n",
      "    # Vectorize the data\n",
      "    x = np.zeros((len(sentences), seq_length, len(chars)), dtype=bool)\n",
      "    y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
      "    for i, sentence in enumerate(sentences):\n",
      "        for t, char in enumerate(sentence):\n",
      "            x[i, t, char_indices[char]] = 1\n",
      "        y[i, char_indices[next_chars[i]]] = 1\n",
      "    ```\n",
      "\n",
      "2.  **Model Building (using Keras with TensorFlow):**\n",
      "\n",
      "    ```python\n",
      "    from tensorflow.keras.models import Sequential\n",
      "    from tensorflow.keras.layers import LSTM, Dense, Activation\n",
      "\n",
      "    # Build the model\n",
      "    model = Sequential()\n",
      "    model.add(LSTM(128, input_shape=(seq_length, len(chars))))\n",
      "    model.add(Dense(len(chars)))\n",
      "    model.add(Activation('softmax'))\n",
      "\n",
      "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
      "    ```\n",
      "\n",
      "    *   **LSTM Layer:**  An LSTM (Long Short-Term Memory) layer is a type of recurrent neural network that is well-suited for processing sequential data.\n",
      "    *   **Dense Layer:**  A dense layer is a fully connected layer.\n",
      "    *   **Softmax Activation:**  The softmax activation function converts the output of the dense layer into a probability distribution over the characters.\n",
      "\n",
      "3.  **Training:**\n",
      "\n",
      "    ```python\n",
      "    # Train the model\n",
      "    model.fit(x, y, batch_size=128, epochs=20)\n",
      "    ```\n",
      "\n",
      "    *   **Batch Size:**  The number of sequences to process in each batch.\n",
      "    *   **Epochs:**  The number of times to iterate over the entire dataset.\n",
      "\n",
      "4.  **Text Generation:**\n",
      "\n",
      "    ```python\n",
      "    # Function to generate text\n",
      "    def sample(preds, temperature=1.0):\n",
      "        # helper function to sample an index from a probability array\n",
      "        preds = np.asarray(preds).astype('float64')\n",
      "        preds = np.log(preds) / temperature\n",
      "        exp_preds = np.exp(preds)\n",
      "        preds = exp_preds / np.sum(exp_preds)\n",
      "        probas = np.random.multinomial(1, preds, 1)\n",
      "        return np.argmax(probas)\n",
      "\n",
      "    def generate_text(length, temperature):\n",
      "        start_index = np.random.randint(0, len(text) - seq_length - 1)\n",
      "        generated = ''\n",
      "        sentence = text[start_index: start_index + seq_length]\n",
      "        generated += sentence\n",
      "        for i in range(length):\n",
      "            x_pred = np.zeros((1, seq_length, len(chars)))\n",
      "            for t, char in enumerate(sentence):\n",
      "                x_pred[0, t, char_indices[char]] = 1.\n",
      "\n",
      "            preds = model.predict(x_pred, verbose=0)[0]\n",
      "            next_index = sample(preds, temperature)\n",
      "            next_char = indices_char[next_index]\n",
      "\n",
      "            generated += next_char\n",
      "            sentence = sentence[1:] + next_char\n",
      "        return generated\n",
      "\n",
      "    # Generate text\n",
      "    print(generate_text(400, 0.5))\n",
      "    ```\n",
      "\n",
      "    *   **Temperature:**  A parameter that controls the randomness of the generated text.  A higher temperature will result in more random text, while a lower temperature will result in more predictable text.\n",
      "\n",
      "**IV.  Moving Towards More Advanced Models:**\n",
      "\n",
      "*   **Word-Level Models:** Instead of characters, use words as the basic unit. This requires more data and computational power but can produce more coherent text.\n",
      "*   **Embeddings:** Use pre-trained word embeddings (like Word2Vec, GloVe, or FastText) to represent words as vectors. This can significantly improve performance.\n",
      "*   **Transformers:**  Learn about the Transformer architecture and use the Hugging Face Transformers library to fine-tune pre-trained Transformer models (like BERT, GPT-2, or GPT-3) on your own data. This is the most common approach for building state-of-the-art language models.\n",
      "*   **Larger Datasets:**  The more data you have, the better your model will perform.\n",
      "*   **More Computational Resources:**  Training larger models requires more powerful hardware (GPUs or TPUs).\n",
      "\n",
      "**V. Challenges and Considerations:**\n",
      "\n",
      "*   **Data Acquisition and Cleaning:**  Finding and cleaning large datasets can be time-consuming and challenging.\n",
      "*   **Computational Resources:**  Training large language models requires significant computational resources.\n",
      "*   **Bias and Fairness:**  Language models can inherit biases from the data they are trained on.  It's important to be aware of these biases and take steps to mitigate them.\n",
      "*   **Ethical Considerations:**  Language models can be used for malicious purposes, such as generating fake news or spam.  It's important to use these models responsibly.\n",
      "\n",
      "**VI. Resources:**\n",
      "\n",
      "*   **Online Courses:** Coursera, edX, Udacity, and fast.ai offer courses on deep learning and NLP.\n",
      "*   **Books:** \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville; \"Natural Language Processing with Python\" by Steven Bird, Ewan Klein, and Edward Loper.\n",
      "*   **Tutorials:** The TensorFlow and PyTorch websites have excellent tutorials.  The Hugging Face Transformers documentation is also very helpful.\n",
      "*   **Research Papers:**  Read research papers on language modeling to stay up-to-date on the latest advances.\n",
      "\n",
      "**Important Notes:**\n",
      "\n",
      "*   **Start Small:** Don't try to build a massive model right away. Start with a small, simple model and gradually increase its complexity.\n",
      "*   **Experiment:**  Try different architectures, hyperparameters, and training techniques to see what works best.\n",
      "*   **Be Patient:**  Training language models can take a long time.\n",
      "*   **Learn from Others:**  Read blog posts, tutorials, and research papers to learn from the experiences of others.\n",
      "\n",
      "Building a language model is a challenging but rewarding project.  By following these steps and dedicating yourself to learning, you can gain a deep understanding of this fascinating field. Good luck!\n"
     ]
    }
   ],
   "source": [
    "print(output['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023607e",
   "metadata": {},
   "source": [
    "### Memory for Multi-turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d8d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c8583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e96d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11903d0a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# chat node\n",
    "def model_node(state):\n",
    "    summary = state.get(\"summary\",'')\n",
    "    if summary:\n",
    "        system_message = f\"Summmary of previous chat : {summary}\"\n",
    "        messages = [SystemMessage(system_message)] + state['messages']\n",
    "    else:\n",
    "        messages = state['messages']\n",
    "        \n",
    "    return {'messages': [llm.invoke(messages)]}\n",
    "\n",
    "# Summaraize node\n",
    "def summary_node(state):\n",
    "    summarize_prompt = [HumanMessage('Summarize the whole chat until now , so it can be used as chat history, only generate summary nothing else')]\n",
    "    history_chat = state['messages']\n",
    "    model_input_for_summary = history_chat + summarize_prompt\n",
    "    return {\"summary\": llm.invoke(model_input_for_summary)}\n",
    "\n",
    "def condition(state):\n",
    "    if len(state['messages']) > 4:\n",
    "        return \"summary_node\"\n",
    "    else:\n",
    "        return END \n",
    "\n",
    "# Graph nodes and connections\n",
    "graph.add_node('model_node', model_node)\n",
    "graph.add_node(summary_node)\n",
    "\n",
    "graph.add_edge(START, 'model_node')\n",
    "graph.add_conditional_edges('model_node', condition)\n",
    "\n",
    "graph.add_edge('summary_node', END)\n",
    "\n",
    "# Compile graph\n",
    "graph = graph.compile(checkpointer=memory)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e9c5ae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StateGraph' object has no attribute 'get_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m()\u001b[38;5;241m.\u001b[39mdraw_mermaid_png()))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StateGraph' object has no attribute 'get_graph'"
     ]
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a22872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}, id='74b1c451-f79b-478a-b022-96c35600d85c'),\n",
       "  AIMessage(content='I am a large language model, trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--14017446-d838-416d-bd06-5ea3a643e05e-0', usage_metadata={'input_tokens': 3, 'output_tokens': 12, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofig = {'configurable': {'thread_id':1}}\n",
    "graph.invoke({'messages': {'role':'user','content':'who are you'}},config=cofig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1acc6a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}, id='74b1c451-f79b-478a-b022-96c35600d85c'),\n",
       "  AIMessage(content='I am a large language model, trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--14017446-d838-416d-bd06-5ea3a643e05e-0', usage_metadata={'input_tokens': 3, 'output_tokens': 12, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='who built you', additional_kwargs={}, response_metadata={}, id='8cf88c0e-1593-48c5-9377-fac687557722'),\n",
       "  AIMessage(content='I was trained by Google.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--cd1cf627-fff0-4cbd-88cb-56de8e7ec093-0', usage_metadata={'input_tokens': 17, 'output_tokens': 7, 'total_tokens': 24, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'messages' : [HumanMessage('who built you')]},config=cofig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24d63b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8a43f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4595c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6957f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f12aa336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e8262bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! It's nice to meet you. How can I help you today?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Lance. You just told me! \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's awesome! They're a great team. What do you like most about the 49ers? Are you excited for the upcoming season?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"i like the 49ers!\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe7d42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='5e84b096-59a1-4f62-b253-f57a07682900'), AIMessage(content=\"Hi Lance! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--9d96b000-d7f6-43e0-9898-9c230cbc9f7e-0', usage_metadata={'input_tokens': 6, 'output_tokens': 19, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}}), HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='bdef8595-03ef-4416-9dff-3f8697290f9f'), AIMessage(content='Your name is Lance. You just told me! ', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--b39318ef-fcf5-4041-a0fb-300de46b95b2-0', usage_metadata={'input_tokens': 30, 'output_tokens': 12, 'total_tokens': 42, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='i like the 49ers!', additional_kwargs={}, response_metadata={}, id='dc4331d9-6377-4d63-9d42-103a3de1b73a'), AIMessage(content=\"That's awesome! They're a great team. What do you like most about the 49ers? Are you excited for the upcoming season?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--dc425dba-c8f2-46ed-a2b3-cfde904b8afe-0', usage_metadata={'input_tokens': 49, 'output_tokens': 33, 'total_tokens': 82, 'input_token_details': {'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f02af68-7089-6612-8007-5d270b82a73c'}}, metadata={'source': 'loop', 'writes': {'conversation': {'messages': AIMessage(content=\"That's awesome! They're a great team. What do you like most about the 49ers? Are you excited for the upcoming season?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--dc425dba-c8f2-46ed-a2b3-cfde904b8afe-0', usage_metadata={'input_tokens': 49, 'output_tokens': 33, 'total_tokens': 82, 'input_token_details': {'cache_read': 0}})}}, 'step': 7, 'parents': {}, 'thread_id': '1'}, created_at='2025-05-07T03:51:16.429320+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f02af68-63b9-66c6-8006-e3107ef01965'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45627c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "278a9734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You're right, Nick Bosa is a fantastic player! And yes, he is currently the highest-paid defensive player in the NFL. He signed a massive contract extension that made him the highest-paid at his position. He's definitely a key part of the 49ers' success.\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"i like Nick Bosa, isn't he the highest paid defensive player?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e69eb3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, here's a summary of our conversation:\\n\\nLance introduced himself. I acknowledged him and asked how I could help. He then asked me what his name was, and I reminded him that he had just told me it was Lance. He then stated he likes the 49ers, and I responded positively, asking what he liked about them and if he was excited for the season. He replied that he likes Nick Bosa and asked if he was the highest-paid defensive player, to which I confirmed that he is.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9034a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4f8cc91",
   "metadata": {},
   "source": [
    "### simple web rag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff573029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    context:Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b896888",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "# Nodes\n",
    "def duckduckgo_search(state):\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    question = state['question']\n",
    "    search_result = search.invoke(question)\n",
    "    return {'context': [search_result]}\n",
    "\n",
    "def wiki_search(state):\n",
    "    question = state['question']\n",
    "    documents = WikipediaLoader(question, load_max_docs=3).load()\n",
    "    search_result = []\n",
    "    for doc in documents:\n",
    "        search_result.append(doc.metadata['summary'])\n",
    "    \n",
    "    return {'context':  search_result}\n",
    "\n",
    "def model_call(state):\n",
    "    context = '\\n'.join(state['context'])\n",
    "    prompt = (f\"context: {context}\\n Answer the question: {state['question']} using the context above, if the answer does not present in the context say it\")\n",
    "    return {'answer': model.invoke(prompt)}\n",
    "\n",
    "graph.add_node('wiki', wiki_search)\n",
    "graph.add_node('duck',duckduckgo_search)\n",
    "graph.add_node('model', model_call)\n",
    "\n",
    "graph.add_edge(START, 'wiki')\n",
    "graph.add_edge(START, 'duck')\n",
    "graph.add_edge('wiki', 'model')\n",
    "graph.add_edge('duck','model')\n",
    "graph.add_edge('model',END)\n",
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b17a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({'question':'what is algebra in mathematics'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algebra is the branch of mathematics that studies algebraic structures and the operations they use. [1] An algebraic structure is a non-empty set of mathematical objects, such as the integers, together with algebraic operations defined on that set, like addition and multiplication. [2] [a] Algebra explores the laws, general characteristics, and types of algebraic structures. Algebra is the branch of mathematics with the following properties. Deals with symbols (or variables) and rules for manipulating these symbols. Elementary (Taught in Schools) Algebra mainly deals with variables and operations like sum, power, subtraction, etc. algebra, branch of mathematics in which arithmetical operations and formal manipulations are applied to abstract symbols rather than specific numbers. The notion that there exists such a distinct subdiscipline of mathematics, as well as the term algebra to denote it, resulted from a slow historical development. This article presents that history, tracing the evolution over time of the concept ... Algebra is the branch of mathematics that helps in the representation of problems or situations in the form of mathematical expressions. It involves variables like x, y, z, and mathematical operations like addition, subtraction, multiplication, and division to form a meaningful mathematical expression. All the branches of mathematics such as ... Elementary algebra is a math branch that deals with the basic traits of numbers and their connections. Algebra plays a crucial role in advanced math and statistics natural sciences, computer science, economics, and business. Like writing, algebra is vital to modern scientific and technological advances.Algebra is a branch of mathematics that deals with abstract systems, known as algebraic structures, and the manipulation of expressions within those systems. It is a generalization of arithmetic that introduces variables and algebraic operations other than the standard arithmetic operations, such as addition and multiplication.\n",
      "Elementary algebra is the main form of algebra taught in schools. It examines mathematical statements using variables for unspecified values and seeks to determine for which values the statements are true. To do so, it uses different methods of transforming equations to isolate variables. Linear algebra is a closely related field that investigates linear equations and combinations of them called systems of linear equations. It provides methods to find the values that solve all equations in the system at the same time, and to study the set of these solutions.\n",
      "Abstract algebra studies algebraic structures, which consist of a set of mathematical objects together with one or several operations defined on that set. It is a generalization of elementary and linear algebra since it allows mathematical objects other than numbers and non-arithmetic operations. It distinguishes between different types of algebraic structures, such as groups, rings, and fields, based on the number of operations they use and the laws they follow, called axioms. Universal algebra and category theory provide general frameworks to investigate abstract patterns that characterize different classes of algebraic structures.\n",
      "Algebraic methods were first studied in the ancient period to solve specific problems in fields like geometry. Subsequent mathematicians examined general techniques to solve equations independent of their specific applications. They described equations and their solutions using words and abbreviations until the 16th and 17th centuries when a rigorous symbolic formalism was developed. In the mid-19th century, the scope of algebra broadened beyond a theory of equations to cover diverse types of algebraic operations and structures. Algebra is relevant to many branches of mathematics, such as geometry, topology, number theory, and calculus, and other fields of inquiry, like logic and the empirical sciences.\n",
      "\n",
      "Mathematics is a field of study that discovers and organizes methods, theories and theorems that are developed and proved for the needs of empirical sciences and mathematics itself. There are many areas of mathematics, which include number theory (the study of numbers), algebra (the study of formulas and related structures), geometry (the study of shapes and spaces that contain them), analysis (the study of continuous changes), and set theory (presently used as a foundation for all mathematics).\n",
      "Mathematics involves the description and manipulation of abstract objects that consist of either abstractions from nature orin modern mathematicspurely abstract entities that are stipulated to have certain properties, called axioms.  Mathematics uses pure reason to prove properties of objects, a proof consisting of a succession of applications of deductive rules to already established results. These results include previously proved theorems, axioms, andin case of abstraction from naturesome basic properties that are considered true starting points of the theory under consideration.\n",
      "Mathematics is essential in the natural sciences, engineering, medicine, finance, computer science, and the social sciences. Although mathematics is extensively used for modeling phenomena, the fundamental truths of mathematics are independent of any scientific experimentation. Some areas of mathematics, such as statistics and game theory, are developed in close correlation with their applications and are often grouped under applied mathematics. Other areas are developed independently from any application (and are therefore called pure mathematics) but often later find practical applications.\n",
      "Historically, the concept of a proof and its associated mathematical rigour first appeared in Greek mathematics, most notably in Euclid's Elements. Since its beginning, mathematics was primarily divided into geometry and arithmetic (the manipulation of natural numbers and fractions), until the 16th and 17th centuries, when algebra and infinitesimal calculus were introduced as new fields. Since then, the interaction between mathematical innovations and scientific discoveries has led to a correlated increase in the development of both. At the end of the 19th century, the foundational crisis of mathematics led to the systematization of the axiomatic method, which heralded a dramatic increase in the number of mathematical areas and their fields of application. The contemporary Mathematics Subject Classification lists more than sixty first-level areas of mathematics.\n",
      "\n",
      "Algebra can essentially be considered as doing computations similar to those of arithmetic but with non-numerical mathematical objects. However, until the 19th century, algebra consisted essentially of the theory of equations. For example, the fundamental theorem of algebra belongs to the theory of equations and is not, nowadays, considered as belonging to algebra (in fact, every proof must use the completeness of the real numbers, which is not an algebraic property).\n",
      "This article describes the history of the theory of equations, referred to in this article as \"algebra\", from the origins to the emergence of algebra as a separate area of mathematics.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(''.join(result['context']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0817e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "question = 'algebra'\n",
    "search_result = search.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00e20664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Algebra is a branch of mathematics that studies abstract systems and operations. Learn about its origin, development, and major branches, such as elementary, linear, and abstract algebra. Learn about the origin and evolution of algebra, the branch of mathematics that manipulates abstract symbols rather than numbers. Explore the ancient and modern developments of equations, number systems, and symbolic language in algebra. Algebra did not always make use of the symbolism that is now ubiquitous in mathematics; instead, it went through three distinct stages. The stages in the development of symbolic algebra are approximately as follows: [3] Rhetorical algebra, in which equations are written in full sentences. For example, the rhetorical form of x + 1 = 2 {\\\\displaystyle x+1=2} is \"The thing plus one equals two\" or ... Learn the basics of algebra, including expressions, equations, operations, and methods for solving linear and quadratic equations. Explore algebra formulas, tricks, practice questions, and coding solutions for programmers. Learn the fundamentals of algebra, such as variables, expressions, equations, and operations. Find examples of linear, quadratic, and cubic equations, and how to solve them using algebraic rules and methods.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a91dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
